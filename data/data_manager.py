"""
Module de gestion des donn√©es pour QAAF
Int√®gre les meilleures pratiques Yahoo Finance
"""

import pandas as pd
import numpy as np
import os
from typing import Dict, Optional, List, Tuple
import logging
import yfinance as yf
from datetime import datetime

logger = logging.getLogger(__name__)


def standardize_yahoo_data(data: pd.DataFrame) -> pd.DataFrame:
    """
    Standardise les donn√©es Yahoo Finance pour garantir la coh√©rence
    
    G√®re:
    - MultiIndex (quand yfinance retourne plusieurs niveaux de colonnes)
    - Conversion des noms de colonnes en minuscules
    - Validation de la structure
    
    Args:
        data: DataFrame brut de yfinance
    
    Returns:
        DataFrame standardis√© avec colonnes en minuscules
    
    Raises:
        ValueError: Si les donn√©es sont vides ou invalides
    """
    if data.empty:
        raise ValueError("DataFrame vide fourni √† standardize_yahoo_data")
    
    # Copie pour ne pas modifier l'original
    df = data.copy()
    
    # CRITIQUE: Aplatir le MultiIndex si pr√©sent
    if isinstance(df.columns, pd.MultiIndex):
        # Prendre le premier niveau (les noms de colonnes: Open, High, Low, Close, Volume)
        df.columns = df.columns.droplevel(1)
        logger.debug("MultiIndex aplati en Index simple")
    
    # Convertir tous les noms de colonnes en minuscules
    df.columns = df.columns.str.lower()
    
    return df


def validate_yahoo_data(df: pd.DataFrame, symbol: str) -> None:
    """
    Valide que les donn√©es Yahoo Finance contiennent toutes les colonnes requises
    
    Args:
        df: DataFrame √† valider
        symbol: Symbole de l'actif (pour les messages d'erreur)
    
    Raises:
        ValueError: Si des colonnes requises sont manquantes
    """
    required_columns = {'open', 'high', 'low', 'close', 'volume'}
    actual_columns = set(df.columns)
    
    missing_columns = required_columns - actual_columns
    
    if missing_columns:
        raise ValueError(
            f"Colonnes manquantes pour {symbol}: {missing_columns}. "
            f"Colonnes pr√©sentes: {actual_columns}"
        )
    
    logger.debug(f"Validation r√©ussie pour {symbol}: toutes les colonnes OHLCV pr√©sentes")


class DataManager:
    """
    Gestionnaire des donn√©es pour QAAF

    Cette classe s'occupe de:
    - Charger les donn√©es depuis des sources externes (Yahoo Finance)
    - Stocker et r√©cup√©rer les donn√©es en cache
    - Standardiser et valider les donn√©es
    - Pr√©parer les donn√©es pour l'analyse QAAF
    """

    def __init__(self,
                 data_dir: str = "./data/historical",
                 use_cache: bool = True):
        """
        Initialise le gestionnaire de donn√©es

        Args:
            data_dir: R√©pertoire de stockage des donn√©es
            use_cache: Utiliser le cache pour √©viter les t√©l√©chargements r√©p√©t√©s
        """
        self.data_dir = data_dir
        self.use_cache = use_cache
        self.data_cache = {}

        # Cr√©ation du r√©pertoire de donn√©es s'il n'existe pas
        os.makedirs(data_dir, exist_ok=True)
        
        logger.info(f"DataManager initialis√© (cache: {use_cache}, dir: {data_dir})")

    def _get_cache_path(self, symbol: str, start_date: str, end_date: str) -> str:
        """
        G√©n√®re le chemin pour le fichier de cache

        Args:
            symbol: Symbole de l'actif
            start_date: Date de d√©but
            end_date: Date de fin

        Returns:
            Chemin du fichier de cache
        """
        cache_filename = f"{symbol}_{start_date}_{end_date}.csv"
        return os.path.join(self.data_dir, cache_filename)

    def get_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        R√©cup√®re les donn√©es pour un symbole avec standardisation Yahoo Finance

        Tente d'abord de charger depuis le cache, sinon t√©l√©charge les donn√©es

        Args:
            symbol: Symbole de l'actif (ex: 'BTC-USD', 'PAXG-USD')
            start_date: Date de d√©but (format: 'YYYY-MM-DD')
            end_date: Date de fin (format: 'YYYY-MM-DD')

        Returns:
            DataFrame standardis√© avec colonnes: open, high, low, close, volume
        
        Raises:
            ValueError: Si les donn√©es sont invalides ou vides
            RuntimeError: Si le t√©l√©chargement √©choue
        """
        # V√©rification du cache en m√©moire
        cache_key = f"{symbol}_{start_date}_{end_date}"
        if cache_key in self.data_cache:
            logger.info(f"‚úÖ {symbol}: Charg√© depuis cache m√©moire")
            return self.data_cache[cache_key]

        # V√©rification du cache sur disque
        cache_path = self._get_cache_path(symbol, start_date, end_date)
        if self.use_cache and os.path.exists(cache_path):
            try:
                df = pd.read_csv(cache_path, index_col=0, parse_dates=True)
                
                # Validation du cache
                validate_yahoo_data(df, symbol)
                
                self.data_cache[cache_key] = df
                logger.info(f"‚úÖ {symbol}: Charg√© depuis cache disque ({len(df)} jours)")
                return df
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Cache corrompu pour {symbol}, re-t√©l√©chargement: {e}")
                # Supprimer le cache corrompu
                try:
                    os.remove(cache_path)
                except:
                    pass

        # T√©l√©chargement des donn√©es depuis Yahoo Finance
        try:
            logger.info(f"üì• T√©l√©chargement {symbol} ({start_date} ‚Üí {end_date})")
            
            # T√©l√©chargement avec param√®tres explicites
            raw_data = yf.download(
                symbol,
                start=start_date,
                end=end_date,
                progress=False,
                auto_adjust=True  # √âvite le warning et simplifie les donn√©es
            )

            if raw_data.empty:
                raise ValueError(f"Aucune donn√©e retourn√©e par Yahoo Finance pour {symbol}")

            # STANDARDISATION (g√®re le MultiIndex automatiquement)
            df = standardize_yahoo_data(raw_data)
            
            # VALIDATION
            validate_yahoo_data(df, symbol)
            
            # Informations de debug
            logger.info(
                f"‚úÖ {symbol}: {len(df)} jours charg√©s "
                f"({df.index[0].date()} ‚Üí {df.index[-1].date()})"
            )
            logger.debug(f"   Colonnes: {list(df.columns)}")
            logger.debug(f"   Prix moyen: ${df['close'].mean():.2f}")

            # Sauvegarde dans le cache disque
            if self.use_cache:
                df.to_csv(cache_path)
                logger.debug(f"üíæ Cache disque cr√©√©: {os.path.basename(cache_path)}")

            # Mise en cache m√©moire
            self.data_cache[cache_key] = df

            return df

        except ValueError as e:
            # Erreur de validation ou donn√©es vides
            logger.error(f"‚ùå Donn√©es invalides pour {symbol}: {e}")
            raise
        except Exception as e:
            # Erreur de t√©l√©chargement ou autre
            logger.error(f"‚ùå Erreur t√©l√©chargement {symbol}: {type(e).__name__}: {e}")
            raise RuntimeError(f"Impossible de charger {symbol}: {e}")

    def prepare_qaaf_data(self, start_date: str, end_date: str) -> Dict[str, pd.DataFrame]:
        """
        Pr√©pare toutes les donn√©es n√©cessaires pour l'analyse QAAF:
        - BTC-USD
        - PAXG-USD
        - PAXG/BTC (ratio calcul√©)

        Args:
            start_date: Date de d√©but (format: 'YYYY-MM-DD')
            end_date: Date de fin (format: 'YYYY-MM-DD')

        Returns:
            Dictionnaire avec les cl√©s:
            - 'BTC': DataFrame des donn√©es Bitcoin
            - 'PAXG': DataFrame des donn√©es PAXG (or tokenis√©)
            - 'PAXG/BTC': DataFrame du ratio PAXG/BTC
        
        Raises:
            ValueError: Si les donn√©es sont invalides ou incompatibles
        """
        logger.info("=" * 60)
        logger.info("üìä Pr√©paration des donn√©es QAAF")
        logger.info(f"   P√©riode: {start_date} ‚Üí {end_date}")
        logger.info("=" * 60)
        
        # R√©cup√©ration des donn√©es individuelles
        btc_data = self.get_data('BTC-USD', start_date, end_date)
        paxg_data = self.get_data('PAXG-USD', start_date, end_date)

        # Alignement des indices temporels (strictement BTC ‚à© PAXG)
        common_index = btc_data.index.intersection(paxg_data.index)

        if len(common_index) == 0:
            raise ValueError(
                f"Aucune date commune entre BTC et PAXG. "
                f"BTC: {len(btc_data)} jours, PAXG: {len(paxg_data)} jours"
            )

        # Filtrer sur les dates communes et remplir NaN si n√©cessaire
        btc_data = btc_data.reindex(common_index).ffill().bfill()
        paxg_data = paxg_data.reindex(common_index).ffill().bfill()

        logger.info(f"‚úÖ Alignement temporel: {len(common_index)} jours communs")

        # Calcul du ratio PAXG/BTC
        paxg_btc_ratio = paxg_data['close'] / btc_data['close']

        # Cr√©ation d'un DataFrame complet pour PAXG/BTC (index√© sur common_index)
        paxg_btc_data = pd.DataFrame({
            'open': paxg_data['open'] / btc_data['open'],
            'high': paxg_data['high'] / btc_data['high'],
            'low': paxg_data['low'] / btc_data['low'],
            'close': paxg_btc_ratio,
            'volume': paxg_data['volume']  # Approximation
        }, index=common_index)

        # Statistiques du ratio (debug)
        ratio_mean = paxg_btc_ratio.mean()
        ratio_std = paxg_btc_ratio.std()
        ratio_min = paxg_btc_ratio.min()
        ratio_max = paxg_btc_ratio.max()

        logger.info(f"üìä Ratio PAXG/BTC calcul√©:")
        logger.info(f"   Moyenne: {ratio_mean:.6f} (¬±{ratio_std:.6f})")
        logger.info(f"   Min: {ratio_min:.6f}, Max: {ratio_max:.6f}")
        logger.info(f"   Variation: {((ratio_max/ratio_min - 1) * 100):.1f}%")

        logger.info("‚úÖ Pr√©paration des donn√©es QAAF termin√©e")
        logger.info("=" * 60)

        return {
            'BTC': btc_data,
            'PAXG': paxg_data,
            'PAXG/BTC': paxg_btc_data
        }


    def clear_cache(self, memory_only: bool = False):
        """
        Vide le cache des donn√©es

        Args:
            memory_only: Si True, vide uniquement le cache m√©moire
                        Si False, vide aussi le cache disque
        """
        # Vider le cache m√©moire
        cache_size = len(self.data_cache)
        self.data_cache = {}
        logger.info(f"üßπ Cache m√©moire vid√© ({cache_size} entr√©es supprim√©es)")

        # Vider √©galement le cache disque si demand√©
        if not memory_only:
            count = 0
            for file in os.listdir(self.data_dir):
                if file.endswith('.csv'):
                    try:
                        os.remove(os.path.join(self.data_dir, file))
                        count += 1
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è  Impossible de supprimer {file}: {e}")
            
            logger.info(f"üßπ Cache disque vid√© ({count} fichiers supprim√©s)")


# Fonction utilitaire pour test rapide
def test_data_manager():
    """Test rapide du DataManager avec gestion des erreurs"""
    print("\nüß™ Test du DataManager\n")
    
    manager = DataManager(use_cache=False)  # Pas de cache pour le test
    
    try:
        # Test BTC
        print("Test BTC-USD...")
        btc = manager.get_data('BTC-USD', '2024-01-01', '2024-01-10')
        print(f"‚úÖ BTC: {len(btc)} jours, colonnes: {list(btc.columns)}")
        
        # Test PAXG
        print("\nTest PAXG-USD...")
        paxg = manager.get_data('PAXG-USD', '2024-01-01', '2024-01-10')
        print(f"‚úÖ PAXG: {len(paxg)} jours, colonnes: {list(paxg.columns)}")
        
        # Test pr√©paration compl√®te
        print("\nTest pr√©paration QAAF...")
        data = manager.prepare_qaaf_data('2024-01-01', '2024-01-10')
        print(f"‚úÖ QAAF data pr√©par√©: {list(data.keys())}")
        print(f"   Ratio moyen PAXG/BTC: {data['PAXG/BTC']['close'].mean():.6f}")
        
        print("\nüéâ Tous les tests r√©ussis!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Test √©chou√©: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # Lancer le test si ex√©cut√© directement
    test_data_manager()